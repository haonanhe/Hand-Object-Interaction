# Hand-Object-Interaction
Collections of  papers and codes of hand-object interaction (HOI). 

[CVPR 2024] [Paper] [Code] [Project Page]

## HOI Dataset
1. Freihand: A dataset for markerless capture of hand pose and shape from single rgb images. [ICCV 2019] [[Paper]](https://arxiv.org/pdf/1909.04349) [[Code]](https://github.com/lmb-freiburg/freihand) [[Project Page]](https://lmb.informatik.uni-freiburg.de/projects/freihand/)
2. HOnnotate: A method for 3D Annotation of Hand and Object Poses. [CVPR 2020] [[Paper]](https://arxiv.org/pdf/1907.01481) [[Code]](https://github.com/shreyashampali/HOnnotate?tab=readme-ov-file) [[Project Page]](https://www.tugraz.at/institute/icg/research/team-lepetit/research-projects/hand-object-3d-pose-annotation/)
3. DexYCB: A Benchmark for Capturing Hand Grasping of Objects. [CVPR 2021] [[Paper]](https://arxiv.org/pdf/2104.04631) [[Code]](https://github.com/NVlabs/dex-ycb-toolkit) [[Project Page]](https://dex-ycb.github.io/)
4. ARCTIC: A dataset for dexterous bimanual hand object manipulation. [ECCV 2024] [[Paper]](https://download.is.tue.mpg.de/arctic/arctic_april_24.pdf) [[Code]](https://github.com/zc-alexfan/arctic) [[Project Page]](https://arctic.is.tue.mpg.de/)
5. Introducing hot3d: An egocentric dataset for 3d hand and object tracking. [CVPR 2025] [[Paper]](https://arxiv.org/pdf/2411.19167) [[Code]](https://github.com/facebookresearch/hot3d) [[Project Page]](https://facebookresearch.github.io/hot3d/)

## Dexterous Dataset
1. DexGraspNet: A Large-Scale Robotic Dexterous Grasp Dataset for General Objects Based on Simulation. [ICRA 2023] [[Paper]](https://arxiv.org/pdf/2210.02697) [[Code]](https://github.com/PKU-EPIC/DexGraspNet) [[Project Page]](https://pku-epic.github.io/DexGraspNet/)

## Hand Motion Reconstruction
1. End-to-End Human Pose and Mesh Reconstruction with Transformers. [CVPR 2021] [[Paper]](https://arxiv.org/pdf/2012.09760) [[Code]](https://github.com/microsoft/MeshTransformer?tab=readme-ov-file)
2. HaMeR: Hand Mesh Recovery. [CVPR 2024] [[Paper]](https://arxiv.org/pdf/2312.05251) [[Code]](https://github.com/geopavlakos/hamer) [[Project Page]](https://geopavlakos.github.io/hamer/)
3. WiLoR: End-to-end 3D hand localization and reconstruction in-the-wild. [CVPR 2025] [[Paper]](https://arxiv.org/pdf/2409.12259) [[Code]](https://github.com/rolpotamias/WiLoR) [[Project Page]](https://rolpotamias.github.io/WiLoR/)
4. Dyn-HaMR: Recovering 4D Interacting Hand Motion from a Dynamic Camera. [CVPR 2025] [[Paper]](https://arxiv.org/pdf/2412.12861) [[Code]](https://github.com/ZhengdiYu/Dyn-HaMR) [[Project Page]](https://dyn-hamr.github.io/)
5. HaWoR: World-Space Hand Motion Reconstruction from Egocentric Videos. [CVPR 2025] [[Paper]](https://arxiv.org/pdf/2501.02973) [[Code]](https://github.com/ThunderVVV/HaWoR) [[Project Page]](https://hawor-project.github.io/)

## Hand Motion Refinement
1. TOCH: Spatio-Temporal Object-to-Hand Correspondence for Motion Refinement. [ECCV 2022] [[Paper]](https://virtualhumans.mpi-inf.mpg.de/papers/zhou22toch/toch.pdf) [[Code]](https://github.com/kzhou23/toch) [[Project Page]](https://virtualhumans.mpi-inf.mpg.de/toch/)
2. GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion. [ICLR 2024] [[Paper]](https://arxiv.org/pdf/2402.14810) [[Code]](https://github.com/Meowuu7/GeneOH-Diffusion) [[Project Page]](https://meowuu7.github.io/GeneOH-Diffusion/)

## Reconstruct Hand/Object from RGB Images/Videos
1. What's in your hands? 3D Reconstruction of Generic Objects in Hands. [CVPR 2022] [[Paper]](https://arxiv.org/pdf/2204.07153) [[Code]](https://github.com/JudyYe/ihoi) [[Project Page]](https://judyye.github.io/ihoi/)
2. AlignSDF: Pose-Aligned Signed Distance Fields for Hand-Object Reconstruction. [ECCV 2022] [[Paper]](https://arxiv.org/pdf/2207.12909) [[Code]](https://github.com/zerchen/AlignSDF) [[Project Page]](https://zerchen.github.io/projects/alignsdf.html)
3. Diffusion-Guided Reconstruction of Everyday Hand-Object Interaction Clips. [ICCV 2023 Oral] [[Paper]](https://arxiv.org/pdf/2309.05663) [[Code]](https://github.com/JudyYe/diffhoi_v2) [[Project Page]](https://judyye.github.io/diffhoi-www/)
4. gSDF: Geometry-Driven Signed Distance Functions for 3D Hand-Object Reconstruction. [CVPR 2023] [[Paper]](https://arxiv.org/pdf/2304.11970) [[Code]](https://github.com/zerchen/gSDF) [[Project Page]](https://zerchen.github.io/projects/gsdf.html)
5. HOLD: Category-agnostic 3D Reconstruction of Interacting Hands and Objects from Video. [CVPR 2024] [[Paper]](https://arxiv.org/pdf/2311.18448) [[Code]](https://github.com/zc-alexfan/hold) [[Project Page]](https://zc-alexfan.github.io/hold)
6. MOHO: Learning Single-view Hand-held Object Reconstruction with Multi-view Occlusion-Aware Supervision. [CVPR 2024] [[Paper]](https://arxiv.org/pdf/2310.11696) [[Code]](https://github.com/ZhangCYG/MOHO)
7. EasyHOI: Unleashing the Power of Large Models for Reconstructing Hand-Object Interactions in the Wild. [CVPR 2025] [[Paper]](https://arxiv.org/pdf/2411.14280) [[Code]](https://github.com/lym29/EasyHOI) [[Project Page]](https://lym29.github.io/EasyHOI-page/)

## Reconstruct Hand/Object from RGB-D Images/Videos
1. BundleSDF: Neural 6-DoF Tracking and 3D Reconstruction of Unknown Objects. [CVPR 2023] [[Paper]](https://arxiv.org/pdf/2303.14158) [[Code]](https://github.com/NVlabs/BundleSDF) [[Project Page]](https://bundlesdf.github.io/)
   
## Generate HOI Images/Videos

## Object-centric HOI Synthesis

## Human Hand to Robotics Manipulation
